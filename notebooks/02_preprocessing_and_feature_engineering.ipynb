{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b199d16b",
   "metadata": {},
   "source": [
    "# 02 – Preprocessing & Feature Engineering\n",
    "Bu notebook, Loan Prediction projesinde modelleme aşamasına geçmeden önce yapılan tüm veri hazırlama adımlarını içerir. Aşağıdaki işlemler sistematik şekilde uygulanmıştır:\n",
    "* Ham verinin temizlenmesi ve tür dönüşümleri\n",
    "* Değişken sınıflandırması (kategorik, sayısal, flag, num-but-cat, cat-but-car)\n",
    "* Eksik değer işlemleri\n",
    "    * Kategorik → Mode imputasyonu\n",
    "    * Sayısal → StandardScaler + KNN Imputer\n",
    "    * Eksik veri flag'leri\n",
    "* Aykırı değer tespiti ve IQR clipping\n",
    "* Feature Engineering\n",
    "    * Domain tabanlı yeni değişken üretimi\n",
    "    * Oranlar, dönüşümler, log-transformlar\n",
    "* Encoding & Scaling (ColumnTransformer ile)\n",
    "* Feature Selection\n",
    "    * Mutual Information\n",
    "\n",
    "Bu notebook’un çıktıları, modelleme aşamasında (03_modelling.ipynb) doğrudan kullanılmak üzere kayıt altına alınmaktadır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af4b40-b3ce-42e0-bd90-690f059b3ad6",
   "metadata": {},
   "source": [
    "## 1) VERİ HAZIRLIĞI (RAW → CLEANED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bffd7f7c-2366-4ea5-84e9-7973e513f1cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (614, 13)\n",
      "Test shape:  (367, 12)\n",
      "\n",
      "Eksik değer (train):\n",
      "Gender                         13\n",
      "Married                         3\n",
      "Dependents                     15\n",
      "Education                       0\n",
      "Self_Employed                  32\n",
      "ApplicantIncome                 0\n",
      "CoapplicantIncome               0\n",
      "LoanAmount                     22\n",
      "Loan_Amount_Term               14\n",
      "Credit_History                 50\n",
      "Property_Area                   0\n",
      "Loan_Status                     0\n",
      "is_missing_Gender               0\n",
      "is_missing_Married              0\n",
      "is_missing_Dependents           0\n",
      "is_missing_Self_Employed        0\n",
      "is_missing_LoanAmount           0\n",
      "is_missing_Loan_Amount_Term     0\n",
      "is_missing_Credit_History       0\n",
      "dtype: int64\n",
      "\n",
      "Eksik değer (test):\n",
      "Gender                         11\n",
      "Married                         0\n",
      "Dependents                     10\n",
      "Education                       0\n",
      "Self_Employed                  23\n",
      "ApplicantIncome                 0\n",
      "CoapplicantIncome               0\n",
      "LoanAmount                      5\n",
      "Loan_Amount_Term                6\n",
      "Credit_History                 29\n",
      "Property_Area                   0\n",
      "is_missing_Gender               0\n",
      "is_missing_Dependents           0\n",
      "is_missing_Self_Employed        0\n",
      "is_missing_LoanAmount           0\n",
      "is_missing_Loan_Amount_Term     0\n",
      "is_missing_Credit_History       0\n",
      "dtype: int64\n",
      "\n",
      "Train: (491, 18)\n",
      "Validation: (123, 18)\n",
      "Test: (367, 17)\n",
      "\n",
      "✓ Veri Hazırlığı Aşaması Tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 1) Ham Veriyi Yükle\n",
    "train_raw = pd.read_csv(\"../data/raw/train_u6lujuX_CVtuZ9i.csv\")\n",
    "test_raw  = pd.read_csv(\"../data/raw/test_Y3wMUE5_7gLdaTN.csv\")\n",
    "\n",
    "# Çalışma kopyaları (ham veri bozulmasın)\n",
    "data = train_raw.copy()\n",
    "data_test = test_raw.copy()\n",
    "\n",
    "print(\"Train shape:\", data.shape)\n",
    "print(\"Test shape: \", data_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# 2) ID ve Hedef Ayrımı\n",
    "\n",
    "# Hedef değişkeni 0/1 olarak dönüştür\n",
    "data[\"Loan_Status\"] = data[\"Loan_Status\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "TARGET = \"Loan_Status\"\n",
    "\n",
    "# Loan_ID modelde kullanılmayacak → hem train hem testten çıkar\n",
    "if \"Loan_ID\" in data.columns:\n",
    "    data.drop(columns=[\"Loan_ID\"], inplace=True)\n",
    "\n",
    "if \"Loan_ID\" in data_test.columns:\n",
    "    data_test.drop(columns=[\"Loan_ID\"], inplace=True)\n",
    "\n",
    "\n",
    "# 3) Veri Tipi Düzeltmeleri\n",
    "\n",
    "# Numerik coercion yapılacak sütunlar\n",
    "num_cols_to_coerce = [\n",
    "    \"ApplicantIncome\",\n",
    "    \"CoapplicantIncome\",\n",
    "    \"LoanAmount\",\n",
    "    \"Loan_Amount_Term\",\n",
    "    \"Credit_History\"\n",
    "]\n",
    "\n",
    "for col in num_cols_to_coerce:\n",
    "    if col in data.columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "    if col in data_test.columns:\n",
    "        data_test[col] = pd.to_numeric(data_test[col], errors=\"coerce\")\n",
    "\n",
    "if \"Dependents\" in data.columns:\n",
    "    data[\"Dependents\"] = data[\"Dependents\"].replace(\"3+\", \"3\")\n",
    "    data[\"Dependents\"] = pd.to_numeric(data[\"Dependents\"], errors=\"coerce\")\n",
    "\n",
    "if \"Dependents\" in data_test.columns:\n",
    "    data_test[\"Dependents\"] = data_test[\"Dependents\"].replace(\"3+\", \"3\")\n",
    "    data_test[\"Dependents\"] = pd.to_numeric(data_test[\"Dependents\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 4) Eksik Değer Flag Kolonları (Leakage yok → split öncesi yapılır)\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].isnull().any():\n",
    "        flag_name = f\"is_missing_{col}\"\n",
    "        data[flag_name] = data[col].isnull().astype(int)\n",
    "\n",
    "for col in data_test.columns:\n",
    "    if data_test[col].isnull().any():\n",
    "        flag_name = f\"is_missing_{col}\"\n",
    "        data_test[flag_name] = data_test[col].isnull().astype(int)\n",
    "\n",
    "\n",
    "print(\"\\nEksik değer (train):\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\nEksik değer (test):\")\n",
    "print(data_test.isnull().sum())\n",
    "\n",
    "\n",
    "# 5) Train / Validation Ayrımı\n",
    "\n",
    "X_full = data.drop(columns=[TARGET])\n",
    "y_full = data[TARGET]\n",
    "\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(\n",
    "    X_full,\n",
    "    y_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_full\n",
    ")\n",
    "\n",
    "X_test_raw = data_test.copy()\n",
    "\n",
    "print(\"\\nTrain:\", X_train_raw.shape)\n",
    "print(\"Validation:\", X_val_raw.shape)\n",
    "print(\"Test:\", X_test_raw.shape)\n",
    "\n",
    "print(\"\\n✓ Veri Hazırlığı Aşaması Tamamlandı.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31b98e-75ae-490c-844d-0044ddf19690",
   "metadata": {},
   "source": [
    "## 2) DEĞİŞKEN SINIFLANDIRMASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20fb39b9-e2cd-4f63-8309-ccc4e32a0055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== DEĞİŞKEN TÜR ÖZETİ (TRAIN) ======\n",
      "Observation (satır):          491\n",
      "Variables (sütun):            18\n",
      "Cat cols:                     14\n",
      "Num cols:                     4\n",
      "Cat but car (yüksek kard.):   0\n",
      "Num but cat:                  9\n",
      "Datetime cols:                0\n",
      "\n",
      "--- Liste Detayları ---\n",
      "Kategorik kolonlar (cat_cols):\n",
      "['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Dependents', 'Credit_History', 'is_missing_Gender', 'is_missing_Married', 'is_missing_Dependents', 'is_missing_Self_Employed', 'is_missing_LoanAmount', 'is_missing_Loan_Amount_Term', 'is_missing_Credit_History']\n",
      "\n",
      "Sürekli numerik kolonlar (num_cont_cols):\n",
      "['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
      "\n",
      "Binary numerik kolonlar (binary_num_cols):\n",
      "[]\n",
      "\n",
      "Eksik flag kolonları (missing_flag_cols):\n",
      "['is_missing_Gender', 'is_missing_Married', 'is_missing_Dependents', 'is_missing_Self_Employed', 'is_missing_LoanAmount', 'is_missing_Loan_Amount_Term', 'is_missing_Credit_History']\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import (\n",
    "    is_object_dtype,\n",
    "    is_numeric_dtype,\n",
    "    is_bool_dtype,\n",
    "    is_datetime64_any_dtype\n",
    ")\n",
    "\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "\n",
    "\n",
    "    cols = dataframe.columns\n",
    "\n",
    "    # Datetime kolonları\n",
    "    datetime_cols = [c for c in cols if is_datetime64_any_dtype(dataframe[c])]\n",
    "\n",
    "    # 1) Kategorik kolonlar (object veya bool)\n",
    "    cat_cols = [\n",
    "        c for c in cols\n",
    "        if (is_object_dtype(dataframe[c]) or is_bool_dtype(dataframe[c]))\n",
    "        and c not in datetime_cols\n",
    "    ]\n",
    "\n",
    "    # 2) Numerik ama az unique değerli kolonlar (num_but_cat)\n",
    "    num_but_cat = [\n",
    "        c for c in cols\n",
    "        if is_numeric_dtype(dataframe[c])\n",
    "        and dataframe[c].nunique(dropna=True) < cat_th\n",
    "    ]\n",
    "\n",
    "    # 3) Kategorik görünümlü ama yüksek kardinalite (cat_but_car)\n",
    "    cat_but_car = [\n",
    "        c for c in cat_cols\n",
    "        if dataframe[c].nunique(dropna=True) > car_th\n",
    "    ]\n",
    "\n",
    "    # 4) Güncellenmiş kategorik kolonlar\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [c for c in cat_cols if c not in cat_but_car]\n",
    "\n",
    "    # 5) Numerik kolonlar (num_but_cat hariç)\n",
    "    num_cols = [\n",
    "        c for c in cols\n",
    "        if is_numeric_dtype(dataframe[c])\n",
    "        and c not in num_but_cat\n",
    "    ]\n",
    "\n",
    "    print(\"====== DEĞİŞKEN TÜR ÖZETİ (TRAIN) ======\")\n",
    "    print(f\"Observation (satır):          {dataframe.shape[0]}\")\n",
    "    print(f\"Variables (sütun):            {dataframe.shape[1]}\")\n",
    "    print(f\"Cat cols:                     {len(cat_cols)}\")\n",
    "    print(f\"Num cols:                     {len(num_cols)}\")\n",
    "    print(f\"Cat but car (yüksek kard.):   {len(cat_but_car)}\")\n",
    "    print(f\"Num but cat:                  {len(num_but_cat)}\")\n",
    "    print(f\"Datetime cols:                {len(datetime_cols)}\")\n",
    "\n",
    "    return cat_cols, num_cols, cat_but_car, datetime_cols, num_but_cat\n",
    "\n",
    "\n",
    "# Sadece TRAIN üzerinden tür sınıflandırma \n",
    "cat_cols, num_cols, cat_but_car, datetime_cols, num_but_cat = grab_col_names(X_train_raw)\n",
    "\n",
    "# Loan_ID daha önce drop edildi, burada olmamalı. \n",
    "# Yine de kontrol edelim (güvenlik için):\n",
    "for c in [\"Loan_ID\", \"Loan_Status\"]:\n",
    "    if c in cat_cols:\n",
    "        cat_cols.remove(c)\n",
    "    if c in num_cols:\n",
    "        num_cols.remove(c)\n",
    "\n",
    "# Ek yardımcı listeler (modelleme ve preprocessing için)\n",
    "\n",
    "# Eksik veri bayrak kolonları (A aşamasında oluşturmuştuk: is_missing_*)\n",
    "missing_flag_cols = [c for c in X_train_raw.columns if c.startswith(\"is_missing_\")]\n",
    "\n",
    "# Binary (2 sınıflı) numerik kolonlar\n",
    "binary_num_cols = [\n",
    "    c for c in num_cols\n",
    "    if X_train_raw[c].nunique(dropna=True) == 2 and c not in missing_flag_cols\n",
    "]\n",
    "\n",
    "# Geriye kalan “gerçek” sürekli numerikler\n",
    "num_cont_cols = [\n",
    "    c for c in num_cols\n",
    "    if c not in binary_num_cols and c not in missing_flag_cols\n",
    "]\n",
    "\n",
    "print(\"\\n--- Liste Detayları ---\")\n",
    "print(\"Kategorik kolonlar (cat_cols):\")\n",
    "print(cat_cols)\n",
    "\n",
    "print(\"\\nSürekli numerik kolonlar (num_cont_cols):\")\n",
    "print(num_cont_cols)\n",
    "\n",
    "print(\"\\nBinary numerik kolonlar (binary_num_cols):\")\n",
    "print(binary_num_cols)\n",
    "\n",
    "print(\"\\nEksik flag kolonları (missing_flag_cols):\")\n",
    "print(missing_flag_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b4a5a-594f-40d5-b4ea-decfb878f5b4",
   "metadata": {},
   "source": [
    "## 3) EKSİK DEĞER İŞLEME (MISSING VALUE HANDLING)\n",
    "#### - Kategorik: Mode (most_frequent)\n",
    "#### - Sayısal: StandardScaler + KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4590e2b7-5583-4e7f-be05-60adf84f96cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategorik (impute edilecek) kolonlar: ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Dependents', 'Credit_History']\n",
      "Sayısal (KNN ile impute edilecek) kolonlar: ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
      "Flag kolonları (dokunulmayacak): ['is_missing_Gender', 'is_missing_Married', 'is_missing_Dependents', 'is_missing_Self_Employed', 'is_missing_LoanAmount', 'is_missing_Loan_Amount_Term', 'is_missing_Credit_History']\n",
      "\n",
      "Numerik impute sonrası (train) NaN sayıları:\n",
      "ApplicantIncome      0\n",
      "CoapplicantIncome    0\n",
      "LoanAmount           0\n",
      "Loan_Amount_Term     0\n",
      "dtype: int64\n",
      "\n",
      "Numerik impute sonrası (val) NaN sayıları:\n",
      "ApplicantIncome      0\n",
      "CoapplicantIncome    0\n",
      "LoanAmount           0\n",
      "Loan_Amount_Term     0\n",
      "dtype: int64\n",
      "\n",
      "Numerik impute sonrası (test) NaN sayıları:\n",
      "ApplicantIncome      0\n",
      "CoapplicantIncome    0\n",
      "LoanAmount           0\n",
      "Loan_Amount_Term     0\n",
      "dtype: int64\n",
      "\n",
      "Eksik değerler - KNN + Mode sonrası (TRAIN):\n",
      "ApplicantIncome                0\n",
      "CoapplicantIncome              0\n",
      "LoanAmount                     0\n",
      "Loan_Amount_Term               0\n",
      "Gender                         0\n",
      "Married                        0\n",
      "Education                      0\n",
      "Self_Employed                  0\n",
      "Property_Area                  0\n",
      "Dependents                     0\n",
      "Credit_History                 0\n",
      "is_missing_Gender              0\n",
      "is_missing_Married             0\n",
      "is_missing_Dependents          0\n",
      "is_missing_Self_Employed       0\n",
      "is_missing_LoanAmount          0\n",
      "is_missing_Loan_Amount_Term    0\n",
      "is_missing_Credit_History      0\n",
      "dtype: int64\n",
      "\n",
      "Şekiller (impute sonrası):\n",
      "train_imputed: (491, 18)\n",
      "val_imputed:   (123, 18)\n",
      "test_imputed:  (367, 17)\n",
      "\n",
      "✓ C) Eksik Değer İşleme Aşaması Tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1) Kategorik / Sayısal / Flag kolonlarını netleştir\n",
    "cat_cols_no_flags = [c for c in cat_cols if c not in missing_flag_cols]\n",
    "\n",
    "print(\"Kategorik (impute edilecek) kolonlar:\", cat_cols_no_flags)\n",
    "print(\"Sayısal (KNN ile impute edilecek) kolonlar:\", num_cont_cols)\n",
    "print(\"Flag kolonları (dokunulmayacak):\", missing_flag_cols)\n",
    "\n",
    "# 2) KATEGORİK EKSİK DEĞERLER (MODE)\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "cat_imputer.fit(X_train_raw[cat_cols_no_flags]) \n",
    "\n",
    "def impute_categoricals(df):\n",
    "    df_cat = pd.DataFrame(\n",
    "        cat_imputer.transform(df[cat_cols_no_flags]),\n",
    "        columns=cat_cols_no_flags,\n",
    "        index=df.index\n",
    "    )\n",
    "    return df_cat\n",
    "\n",
    "X_train_cat_imp = impute_categoricals(X_train_raw)\n",
    "X_val_cat_imp   = impute_categoricals(X_val_raw)\n",
    "X_test_cat_imp  = impute_categoricals(X_test_raw)\n",
    "\n",
    "# Flag kolonları doğrudan alınacak (0/1, eksik yok)\n",
    "def get_flags(df):\n",
    "    # Sadece df'de gerçekten var olan flag kolonlarını al\n",
    "    cols = [c for c in missing_flag_cols if c in df.columns]\n",
    "    return df[cols].copy() if cols else pd.DataFrame(index=df.index)\n",
    "\n",
    "X_train_flags = get_flags(X_train_raw)\n",
    "X_val_flags   = get_flags(X_val_raw)\n",
    "X_test_flags  = get_flags(X_test_raw)\n",
    "\n",
    "# 3) SAYISAL EKSİK DEĞERLER (StandardScaler + KNNImputer)\n",
    "\n",
    "# Train sayısal verisi\n",
    "num_train = X_train_raw[num_cont_cols].copy()\n",
    "\n",
    "# a) Train ortalamaları\n",
    "train_means = num_train.mean()\n",
    "\n",
    "# b) StandardScaler: önce NaN'leri ortalamayla doldur, sonra scale et\n",
    "scaler = StandardScaler()\n",
    "num_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(num_train.fillna(train_means)),\n",
    "    columns=num_cont_cols,\n",
    "    index=num_train.index\n",
    ")\n",
    "\n",
    "# c) KNN doldurması için NaN pozisyonlarını geri getir\n",
    "for c in num_cont_cols:\n",
    "    num_train_scaled.loc[num_train[c].isna(), c] = np.nan\n",
    "\n",
    "# d) KNNImputer'ı sadece train'de fit et\n",
    "knn = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "num_train_imp_scaled = pd.DataFrame(\n",
    "    knn.fit_transform(num_train_scaled),\n",
    "    columns=num_cont_cols,\n",
    "    index=num_train_scaled.index\n",
    ")\n",
    "\n",
    "# e) Orijinal skala\n",
    "num_train_imp = pd.DataFrame(\n",
    "    scaler.inverse_transform(num_train_imp_scaled),\n",
    "    columns=num_cont_cols,\n",
    "    index=num_train_imp_scaled.index\n",
    ")\n",
    "\n",
    "print(\"\\nNumerik impute sonrası (train) NaN sayıları:\")\n",
    "print(num_train_imp.isnull().sum())\n",
    "\n",
    "# Validation & Test için aynı süreç (fit YOK, sadece transform)\n",
    "\n",
    "def impute_numerics(df):\n",
    "    num_part = df[num_cont_cols].copy()\n",
    "\n",
    "    # 1) Train ortalamalarıyla doldur → scale\n",
    "    num_scaled = pd.DataFrame(\n",
    "        scaler.transform(num_part.fillna(train_means)),\n",
    "        columns=num_cont_cols,\n",
    "        index=num_part.index\n",
    "    )\n",
    "\n",
    "    # 2) NaN pozisyonlarını geri koy\n",
    "    for c in num_cont_cols:\n",
    "        num_scaled.loc[num_part[c].isna(), c] = np.nan\n",
    "\n",
    "    # 3) KNN (train'de fit edilmiş)\n",
    "    num_imp_scaled = pd.DataFrame(\n",
    "        knn.transform(num_scaled),\n",
    "        columns=num_cont_cols,\n",
    "        index=num_part.index\n",
    "    )\n",
    "\n",
    "    # 4) Orijinal skala\n",
    "    num_imp = pd.DataFrame(\n",
    "        scaler.inverse_transform(num_imp_scaled),\n",
    "        columns=num_cont_cols,\n",
    "        index=num_part.index\n",
    "    )\n",
    "\n",
    "    return num_imp\n",
    "\n",
    "X_val_num_imp  = impute_numerics(X_val_raw)\n",
    "X_test_num_imp = impute_numerics(X_test_raw)\n",
    "\n",
    "print(\"\\nNumerik impute sonrası (val) NaN sayıları:\")\n",
    "print(X_val_num_imp.isnull().sum())\n",
    "print(\"\\nNumerik impute sonrası (test) NaN sayıları:\")\n",
    "print(X_test_num_imp.isnull().sum())\n",
    "\n",
    "# 4) PARÇALARI BİRLEŞTİR (NUM + CAT + FLAGS + DİĞER)\n",
    "\n",
    "def rebuild_imputed_df(df_raw, num_imp, cat_imp, flags):\n",
    "    parts = [num_imp, cat_imp]\n",
    "\n",
    "    # Flag kolonları: sadece df_raw içinde gerçekten olanlar\n",
    "    if not flags.empty:\n",
    "        parts.append(flags)\n",
    "\n",
    "    # Num + cat + flag dışında kalan kolonları da ekle (varsa)\n",
    "    used_cols = num_cont_cols + cat_cols_no_flags + [c for c in flags.columns]\n",
    "    other_cols = [c for c in df_raw.columns if c not in used_cols]\n",
    "\n",
    "    if other_cols:\n",
    "        parts.append(df_raw[other_cols])\n",
    "\n",
    "    df_new = pd.concat(parts, axis=1)\n",
    "    return df_new\n",
    "\n",
    "train_imputed = rebuild_imputed_df(X_train_raw, X_train_num_imp := num_train_imp, X_train_cat_imp, X_train_flags)\n",
    "val_imputed   = rebuild_imputed_df(X_val_raw,   X_val_num_imp,   X_val_cat_imp,   X_val_flags)\n",
    "test_imputed  = rebuild_imputed_df(X_test_raw,  X_test_num_imp,  X_test_cat_imp,  X_test_flags)\n",
    "\n",
    "print(\"\\nEksik değerler - KNN + Mode sonrası (TRAIN):\")\n",
    "print(train_imputed.isnull().sum())\n",
    "\n",
    "print(\"\\nŞekiller (impute sonrası):\")\n",
    "print(\"train_imputed:\", train_imputed.shape)\n",
    "print(\"val_imputed:  \", val_imputed.shape)\n",
    "print(\"test_imputed: \", test_imputed.shape)\n",
    "\n",
    "print(\"\\n✓ C) Eksik Değer İşleme Aşaması Tamamlandı.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce9574e-6663-43ed-ba18-9f0f103a8f43",
   "metadata": {},
   "source": [
    "## 4) AYKIRI DEĞER İŞLEME (IQR CLIPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b49d182-bbde-4302-a2f1-dcea3f9f6100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AYKIRI DEĞER BİLGİSİ (IQR - SADECE TRAIN'E GÖRE) ===\n",
      "             Feature  Outlier Count (Train)  Lower Bound  Upper Bound\n",
      "0    ApplicantIncome                     40     -1472.50     10203.50\n",
      "1  CoapplicantIncome                     21     -3361.50      5602.50\n",
      "2         LoanAmount                     32        -1.25       268.75\n",
      "3   Loan_Amount_Term                     74       360.00       360.00\n",
      "\n",
      "✓ IQR Clipping tüm setlere uygulandı.\n",
      "train_final: (491, 18)\n",
      "val_final:   (123, 18)\n",
      "test_final:  (367, 17)\n",
      "\n",
      "=== İSTATİSTİK KARŞILAŞTIRMASI (Öncesi vs Sonrası) ===\n",
      ">>> Önce (train_imputed):\n",
      "                   count         mean          std    min     25%     50%  \\\n",
      "ApplicantIncome    491.0  5529.997963  6457.784318  210.0  2906.0  3859.0   \n",
      "CoapplicantIncome  491.0  1569.537271  2789.523475    0.0     0.0  1032.0   \n",
      "LoanAmount         491.0   147.227291    86.497217    9.0   100.0   128.0   \n",
      "Loan_Amount_Term   491.0   341.474542    65.110838   12.0   360.0   360.0   \n",
      "\n",
      "                      75%      max  \n",
      "ApplicantIncome    5825.0  81000.0  \n",
      "CoapplicantIncome  2241.0  41667.0  \n",
      "LoanAmount          167.5    700.0  \n",
      "Loan_Amount_Term    360.0    480.0  \n",
      "\n",
      ">>> Sonra (train_final):\n",
      "                   count         mean          std    min     25%     50%  \\\n",
      "ApplicantIncome    491.0  4666.254582  2468.388323  210.0  2906.0  3859.0   \n",
      "CoapplicantIncome  491.0  1386.532179  1621.005972    0.0     0.0  1032.0   \n",
      "LoanAmount         491.0   138.866802    58.232606    9.0   100.0   128.0   \n",
      "Loan_Amount_Term   491.0   360.000000     0.000000  360.0   360.0   360.0   \n",
      "\n",
      "                      75%       max  \n",
      "ApplicantIncome    5825.0  10203.50  \n",
      "CoapplicantIncome  2241.0   5602.50  \n",
      "LoanAmount          167.5    268.75  \n",
      "Loan_Amount_Term    360.0    360.00  \n"
     ]
    }
   ],
   "source": [
    "# D) AYKIRI DEĞER İŞLEME (IQR CLIPPING)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sadece numerik değişkenlerde clipping yapılır\n",
    "numeric_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "\n",
    "def iqr_bounds(series):\n",
    "    \"\"\"Bir kolon için IQR tabanlı alt ve üst sınırları hesaplar.\"\"\"\n",
    "    q1, q3 = series.quantile(0.25), series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "# 1) TRAIN üzerinde IQR sınırlarını hesapla\n",
    "bounds = {}\n",
    "outlier_info = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    lower, upper = iqr_bounds(train_imputed[col])\n",
    "    bounds[col] = (lower, upper)\n",
    "\n",
    "    # Train içindeki aykırı değer sayısını hesapla\n",
    "    outlier_count = ((train_imputed[col] < lower) | (train_imputed[col] > upper)).sum()\n",
    "    outlier_info.append([col, outlier_count, lower, upper])\n",
    "\n",
    "\n",
    "# Aykırı değer özet tablosu\n",
    "outlier_df = pd.DataFrame(\n",
    "    outlier_info,\n",
    "    columns=[\"Feature\", \"Outlier Count (Train)\", \"Lower Bound\", \"Upper Bound\"]\n",
    ")\n",
    "\n",
    "print(\"=== AYKIRI DEĞER BİLGİSİ (IQR - SADECE TRAIN'E GÖRE) ===\")\n",
    "print(outlier_df)\n",
    "\n",
    "\n",
    "# 2) TRAIN / VAL / TEST için clipping fonksiyonu\n",
    "def apply_clipping(df, bounds):\n",
    "    df_clipped = df.copy()\n",
    "    for col in numeric_cols:\n",
    "        lower, upper = bounds[col]\n",
    "        df_clipped[col] = df_clipped[col].clip(lower=lower, upper=upper)\n",
    "    return df_clipped\n",
    "\n",
    "\n",
    "# 3) IQR clipping uygula\n",
    "train_final = apply_clipping(train_imputed, bounds)\n",
    "val_final   = apply_clipping(val_imputed, bounds)\n",
    "test_final  = apply_clipping(test_imputed, bounds)\n",
    "\n",
    "print(\"\\n✓ IQR Clipping tüm setlere uygulandı.\")\n",
    "print(\"train_final:\", train_final.shape)\n",
    "print(\"val_final:  \", val_final.shape)\n",
    "print(\"test_final: \", test_final.shape)\n",
    "\n",
    "# Hedef vektörlerini kopyala (Final)\n",
    "y_train_final = y_train.copy()\n",
    "y_val_final   = y_val.copy()\n",
    "\n",
    "# 4) (OPSİYONEL) Clipping öncesi-sonrası istatistik karşılaştırması\n",
    "print(\"\\n=== İSTATİSTİK KARŞILAŞTIRMASI (Öncesi vs Sonrası) ===\")\n",
    "print(\">>> Önce (train_imputed):\")\n",
    "print(train_imputed[numeric_cols].describe().T)\n",
    "\n",
    "print(\"\\n>>> Sonra (train_final):\")\n",
    "print(train_final[numeric_cols].describe().T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f6d8b-00d1-41a0-8c5e-9298902145e2",
   "metadata": {},
   "source": [
    "## 5) FEATURE ENGINEERING (Yeni Özellik Üretimi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef1fa0b-06b0-419b-9873-4a39f92954b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering tamamlandı.\n",
      "X_train_fe shape: (491, 30)\n",
      "X_val_fe shape:   (123, 30)\n",
      "X_test_fe shape:  (367, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murat\\AppData\\Local\\Temp\\ipykernel_18288\\3985671768.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace([np.inf, -np.inf], np.nan)\n"
     ]
    }
   ],
   "source": [
    "train_fe = train_final.copy()\n",
    "val_fe   = val_final.copy()\n",
    "test_fe  = test_final.copy()\n",
    "\n",
    "# 1) Domain Tabanlı Özellikler\n",
    "\n",
    "def add_domain_features(df):\n",
    "    \n",
    "    # Toplam gelir\n",
    "    df[\"Total_Income\"] = df[\"ApplicantIncome\"] + df[\"CoapplicantIncome\"]\n",
    "\n",
    "    # EMI: LoanAmount / Loan_Term\n",
    "    term_safe = df[\"Loan_Amount_Term\"].replace(0, np.nan)\n",
    "    df[\"EMI\"] = df[\"LoanAmount\"] / term_safe\n",
    "\n",
    "    # Kredi başına gelir\n",
    "    amount_safe = df[\"LoanAmount\"].replace(0, np.nan)\n",
    "    df[\"Income_per_Loan\"] = df[\"Total_Income\"] / amount_safe\n",
    "\n",
    "    # Loan term (yıl)\n",
    "    df[\"Loan_Term_Years\"] = df[\"Loan_Amount_Term\"] / 12\n",
    "\n",
    "    # Log dönüşümleri (stabil)\n",
    "    df[\"Log_Total_Income\"] = np.log1p(df[\"Total_Income\"].clip(lower=0))\n",
    "    df[\"Log_LoanAmount\"]   = np.log1p(df[\"LoanAmount\"].clip(lower=0))\n",
    "\n",
    "    # Bağımlı kişi sayısı yüksek mi?\n",
    "    df[\"Many_Dependents\"] = (df[\"Dependents\"] >= 3).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_fe = add_domain_features(train_fe)\n",
    "val_fe   = add_domain_features(val_fe)\n",
    "test_fe  = add_domain_features(test_fe)\n",
    "\n",
    "# 2) Interaction Özellikleri\n",
    "\n",
    "def add_interaction_features(df, eps=1e-6):\n",
    "    # Eş gelir oranı\n",
    "    df[\"Coapplicant_Income_Ratio\"] = df[\"CoapplicantIncome\"] / (df[\"Total_Income\"] + eps)\n",
    "\n",
    "    # Gelir / EMI = ödeme gücü göstergesi\n",
    "    df[\"Income_to_EMI\"] = df[\"Total_Income\"] / (df[\"EMI\"] + eps)\n",
    "\n",
    "    # Kişi başına gelir\n",
    "    dep_safe = (df[\"Dependents\"] + 1).replace(0, np.nan)\n",
    "    df[\"Per_Capita_Income\"] = df[\"Total_Income\"] / dep_safe\n",
    "\n",
    "    return df\n",
    "\n",
    "train_fe = add_interaction_features(train_fe)\n",
    "val_fe   = add_interaction_features(val_fe)\n",
    "test_fe  = add_interaction_features(test_fe)\n",
    "\n",
    "# 2.5) Temizlik (NaN Trap Fix)\n",
    "# Feature Engineering sırasında (özellikle bölme işlemlerinde)\n",
    "# oluşabilecek sonsuz (inf) ve eksik (NaN) değerleri temizliyoruz.\n",
    "\n",
    "def clean_new_features(df):\n",
    "    # Sonsuz değerleri NaN yap\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    # NaN değerleri 0 ile doldur (yeni türetilenler için 0 güvenli bir varsayımdır)\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "train_fe = clean_new_features(train_fe)\n",
    "val_fe   = clean_new_features(val_fe)\n",
    "test_fe  = clean_new_features(test_fe)\n",
    "\n",
    "# 3) Binning (Train’e göre) – quantile cut\n",
    "\n",
    "# Sadece train üzerinde sınırlar\n",
    "income_quantiles = train_fe[\"Total_Income\"].quantile([0, 0.25, 0.5, 0.75, 1]).values\n",
    "loan_quantiles   = train_fe[\"LoanAmount\"].quantile([0, 0.25, 0.5, 0.75, 1]).values\n",
    "\n",
    "# Unique check (aynı değerler varsa bin hatası olmasın diye)\n",
    "income_bins = np.unique(income_quantiles)\n",
    "loan_bins   = np.unique(loan_quantiles)\n",
    "\n",
    "income_labels = [f\"q{i}\" for i in range(1, len(income_bins))]\n",
    "loan_labels   = [f\"q{i}\" for i in range(1, len(loan_bins))]\n",
    "\n",
    "def apply_binning(df):\n",
    "    df[\"Total_Income_bin\"] = pd.cut(\n",
    "        df[\"Total_Income\"],\n",
    "        bins=income_bins,\n",
    "        labels=income_labels,\n",
    "        include_lowest=True,\n",
    "        duplicates=\"drop\"\n",
    "    )\n",
    "\n",
    "    df[\"LoanAmount_bin\"] = pd.cut(\n",
    "        df[\"LoanAmount\"],\n",
    "        bins=loan_bins,\n",
    "        labels=loan_labels,\n",
    "        include_lowest=True,\n",
    "        duplicates=\"drop\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train_fe = apply_binning(train_fe)\n",
    "val_fe   = apply_binning(val_fe)\n",
    "test_fe  = apply_binning(test_fe)\n",
    "\n",
    "# 4) Final FE X/Y Matrisleri (Scaling/Encoding için hazır)\n",
    "\n",
    "X_train_fe = train_fe.copy()\n",
    "X_val_fe   = val_fe.copy()\n",
    "X_test_fe  = test_fe.copy()\n",
    "\n",
    "y_train_fe = y_train_final.copy()\n",
    "y_val_fe   = y_val_final.copy()\n",
    "\n",
    "print(\"Feature Engineering tamamlandı.\")\n",
    "print(\"X_train_fe shape:\", X_train_fe.shape)\n",
    "print(\"X_val_fe shape:  \", X_val_fe.shape)\n",
    "print(\"X_test_fe shape: \", X_test_fe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe232810-2bdd-422d-b17e-a04e859b85be",
   "metadata": {},
   "source": [
    "## 6) ENCODING + SCALING (ColumnTransformer ile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de1237f-55ac-4e77-bc9e-bc3e7713d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot yapılacak kategorik kolonlar: ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Dependents', 'Credit_History']\n",
      "Sayısal (RobustScaler) kolonları: ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Total_Income', 'EMI', 'Income_per_Loan', 'Loan_Term_Years', 'Log_Total_Income', 'Log_LoanAmount', 'Many_Dependents', 'Coapplicant_Income_Ratio', 'Income_to_EMI', 'Per_Capita_Income']\n",
      "Flag kolonları: ['is_missing_Gender', 'is_missing_Married', 'is_missing_Dependents', 'is_missing_Self_Employed', 'is_missing_LoanAmount', 'is_missing_Loan_Amount_Term', 'is_missing_Credit_History']\n",
      "X_train_final shape: (491, 38)\n",
      "X_val_final shape: (123, 38)\n",
      "X_test_final shape: (367, 38)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "\n",
    "TARGET = \"Loan_Status\"  # zaten X'lerde yok ama netlik için\n",
    "\n",
    "# 1) X / y ayrımı (FE sonrası)\n",
    "X_train_fe = train_fe.copy()\n",
    "X_val_fe   = val_fe.copy()\n",
    "X_test_fe  = test_fe.copy()   # test'te hedef yok\n",
    "\n",
    "y_train_fe = y_train_final.copy()\n",
    "y_val_fe   = y_val_final.copy()\n",
    "\n",
    "# 1.1. Kolon hizalama (train → val/test)\n",
    "\n",
    "# Val için eksik kolonları ekle\n",
    "for col in X_train_fe.columns:\n",
    "    if col not in X_val_fe.columns:\n",
    "        X_val_fe[col] = 0\n",
    "\n",
    "# Test için eksik kolonları ekle\n",
    "for col in X_train_fe.columns:\n",
    "    if col not in X_test_fe.columns:\n",
    "        X_test_fe[col] = 0\n",
    "\n",
    "# Eğer val/test içinde train'de olmayan fazladan kolon varsa, onları at\n",
    "extra_val_cols  = [c for c in X_val_fe.columns  if c not in X_train_fe.columns]\n",
    "extra_test_cols = [c for c in X_test_fe.columns if c not in X_train_fe.columns]\n",
    "\n",
    "if extra_val_cols:\n",
    "    X_val_fe = X_val_fe.drop(columns=extra_val_cols)\n",
    "if extra_test_cols:\n",
    "    X_test_fe = X_test_fe.drop(columns=extra_test_cols)\n",
    "\n",
    "# Son olarak kolon sıralarını bire bir aynı yap\n",
    "X_val_fe  = X_val_fe[X_train_fe.columns]\n",
    "X_test_fe = X_test_fe[X_train_fe.columns]\n",
    "\n",
    "# 2) Kolon tiplerine göre listeleri hazırla\n",
    "\n",
    "# Kategorik kolonlar (one-hot)\n",
    "cat_cols_base = [\n",
    "    \"Gender\", \"Married\", \"Education\",\n",
    "    \"Self_Employed\", \"Property_Area\",\n",
    "    \"Dependents\", \"Credit_History\"\n",
    "]\n",
    "cat_cols_enc = [c for c in cat_cols_base if c in X_train_fe.columns]\n",
    "\n",
    "# Flag kolonları (0/1, sadece passthrough)\n",
    "flag_cols_enc = [c for c in missing_flag_cols if c in X_train_fe.columns] #### in flag_cols yerine missing_flag_cols yazıldı\n",
    "\n",
    "# Sayısal kolonlar (RobustScaler)\n",
    "num_cols_enc = [\n",
    "    c for c in X_train_fe.select_dtypes(include=[np.number]).columns\n",
    "    if c not in flag_cols_enc and c not in cat_cols_enc\n",
    "]\n",
    "\n",
    "print(\"One-Hot yapılacak kategorik kolonlar:\", cat_cols_enc)\n",
    "print(\"Sayısal (RobustScaler) kolonları:\", num_cols_enc)\n",
    "print(\"Flag kolonları:\", flag_cols_enc)\n",
    "\n",
    "# 3) ColumnTransformer tanımı\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", RobustScaler(), num_cols_enc),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols_enc),\n",
    "        (\"flag\", \"passthrough\", flag_cols_enc),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# 4) Fit (train) + transform (train/val/test)\n",
    "\n",
    "X_train_final = preprocess.fit_transform(X_train_fe)\n",
    "X_val_final   = preprocess.transform(X_val_fe)\n",
    "X_test_final  = preprocess.transform(X_test_fe)\n",
    "\n",
    "print(\"X_train_final shape:\", X_train_final.shape)\n",
    "print(\"X_val_final shape:\",   X_val_final.shape)\n",
    "print(\"X_test_final shape:\",  X_test_final.shape)\n",
    "\n",
    "# 5) Feature isimlerini çıkarıp DataFrame'e çevir\n",
    "\n",
    "# One-hot sonrası kategorik feature isimleri\n",
    "ohe = preprocess.named_transformers_[\"cat\"]\n",
    "cat_ohe_names = ohe.get_feature_names_out(cat_cols_enc)\n",
    "\n",
    "feature_names = (\n",
    "    list(num_cols_enc) +\n",
    "    list(cat_ohe_names) +\n",
    "    list(flag_cols_enc)\n",
    ")\n",
    "\n",
    "X_train_final_df = pd.DataFrame(X_train_final, columns=feature_names, index=X_train_fe.index)\n",
    "X_val_final_df   = pd.DataFrame(X_val_final,   columns=feature_names, index=X_val_fe.index)\n",
    "X_test_final_df  = pd.DataFrame(X_test_final,  columns=feature_names, index=X_test_fe.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670db0c5-f4f0-47ed-b3ca-a46e75643084",
   "metadata": {},
   "source": [
    "## 7) FEATURE SELECTION – Mutual Information (MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04483209-49e3-4862-afa2-0833fcc72601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_fs shape:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (491, 38)\n",
      "X_val_fs shape:   (123, 38)\n",
      "X_test_fs shape:  (367, 38)\n",
      "\n",
      "=== Mutual Information Skorları (Büyükten Küçüğe) ===\n",
      "Credit_History_1.0             0.128569\n",
      "Credit_History_0.0             0.109738\n",
      "is_missing_LoanAmount          0.045006\n",
      "Married_Yes                    0.035962\n",
      "Property_Area_Rural            0.020308\n",
      "CoapplicantIncome              0.017355\n",
      "is_missing_Credit_History      0.014031\n",
      "Many_Dependents                0.013767\n",
      "Coapplicant_Income_Ratio       0.010365\n",
      "Education_Graduate             0.006973\n",
      "Married_No                     0.004710\n",
      "Property_Area_Urban            0.004572\n",
      "Income_to_EMI                  0.002396\n",
      "Income_per_Loan                0.000916\n",
      "Dependents_2.0                 0.000376\n",
      "is_missing_Married             0.000000\n",
      "is_missing_Gender              0.000000\n",
      "is_missing_Dependents          0.000000\n",
      "Dependents_3.0                 0.000000\n",
      "is_missing_Self_Employed       0.000000\n",
      "is_missing_Loan_Amount_Term    0.000000\n",
      "Dependents_1.0                 0.000000\n",
      "Dependents_0.0                 0.000000\n",
      "ApplicantIncome                0.000000\n",
      "Property_Area_Semiurban        0.000000\n",
      "Self_Employed_Yes              0.000000\n",
      "Self_Employed_No               0.000000\n",
      "Gender_Male                    0.000000\n",
      "Gender_Female                  0.000000\n",
      "Per_Capita_Income              0.000000\n",
      "Log_LoanAmount                 0.000000\n",
      "Log_Total_Income               0.000000\n",
      "Loan_Term_Years                0.000000\n",
      "EMI                            0.000000\n",
      "Total_Income                   0.000000\n",
      "Loan_Amount_Term               0.000000\n",
      "LoanAmount                     0.000000\n",
      "Education_Not Graduate         0.000000\n",
      "dtype: float64\n",
      "\n",
      "En yüksek MI skoruna sahip ilk 20 değişken:\n",
      "Credit_History_1.0           0.128569\n",
      "Credit_History_0.0           0.109738\n",
      "is_missing_LoanAmount        0.045006\n",
      "Married_Yes                  0.035962\n",
      "Property_Area_Rural          0.020308\n",
      "CoapplicantIncome            0.017355\n",
      "is_missing_Credit_History    0.014031\n",
      "Many_Dependents              0.013767\n",
      "Coapplicant_Income_Ratio     0.010365\n",
      "Education_Graduate           0.006973\n",
      "Married_No                   0.004710\n",
      "Property_Area_Urban          0.004572\n",
      "Income_to_EMI                0.002396\n",
      "Income_per_Loan              0.000916\n",
      "Dependents_2.0               0.000376\n",
      "is_missing_Married           0.000000\n",
      "is_missing_Gender            0.000000\n",
      "is_missing_Dependents        0.000000\n",
      "Dependents_3.0               0.000000\n",
      "is_missing_Self_Employed     0.000000\n",
      "dtype: float64\n",
      "\n",
      "Seçilen top-25 feature listesi:\n",
      "['Credit_History_1.0', 'Credit_History_0.0', 'is_missing_LoanAmount', 'Married_Yes', 'Property_Area_Rural', 'CoapplicantIncome', 'is_missing_Credit_History', 'Many_Dependents', 'Coapplicant_Income_Ratio', 'Education_Graduate', 'Married_No', 'Property_Area_Urban', 'Income_to_EMI', 'Income_per_Loan', 'Dependents_2.0', 'is_missing_Married', 'is_missing_Gender', 'is_missing_Dependents', 'Dependents_3.0', 'is_missing_Self_Employed', 'is_missing_Loan_Amount_Term', 'Dependents_1.0', 'Dependents_0.0', 'ApplicantIncome', 'Property_Area_Semiurban']\n",
      "\n",
      "MI sonrası şekiller:\n",
      "X_train_mi: (491, 25)\n",
      "X_val_mi:   (123, 25)\n",
      "X_test_mi:  (367, 25)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# 1) Giriş veri setleri (Encoding + Scaling sonrası)\n",
    "X_train_fs = X_train_final_df.copy()\n",
    "X_val_fs   = X_val_final_df.copy()\n",
    "X_test_fs  = X_test_final_df.copy()\n",
    "\n",
    "y_train_fs = y_train_fe.copy()\n",
    "y_val_fs   = y_val_fe.copy()\n",
    "\n",
    "print(\"X_train_fs shape:\", X_train_fs.shape)\n",
    "print(\"X_val_fs shape:  \", X_val_fs.shape)\n",
    "print(\"X_test_fs shape: \", X_test_fs.shape)\n",
    "\n",
    "# 2) Mutual Information skorlarını hesapla\n",
    "\n",
    "mi_scores = mutual_info_classif(\n",
    "    X_train_fs,\n",
    "    y_train_fs,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mi_series = pd.Series(mi_scores, index=X_train_fs.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n=== Mutual Information Skorları (Büyükten Küçüğe) ===\")\n",
    "print(mi_series)\n",
    "\n",
    "# İstersen ilk N feature'a bakalım (örneğin top 20)\n",
    "TOP_N = 20\n",
    "print(f\"\\nEn yüksek MI skoruna sahip ilk {TOP_N} değişken:\")\n",
    "print(mi_series.head(TOP_N))\n",
    "\n",
    "# 3) Eşik / Top-K seçimi ile feature subset oluşturma\n",
    "\n",
    "# Seçim 1: Top-K feature (örnek: en iyi 25 değişken)\n",
    "TOP_K = 25\n",
    "top_k_features = mi_series.head(TOP_K).index.tolist()\n",
    "\n",
    "print(f\"\\nSeçilen top-{TOP_K} feature listesi:\")\n",
    "print(top_k_features)\n",
    "\n",
    "# Alternatif: MI skoruna göre eşik belirleme\n",
    "# örn: mi_series[mi_series > 0.01].index.tolist()\n",
    "\n",
    "# 4) Son X matrislerini bu seçilen feature'lara göre daralt\n",
    "\n",
    "X_train_mi = X_train_fs[top_k_features].copy()\n",
    "X_val_mi   = X_val_fs[top_k_features].copy()\n",
    "X_test_mi  = X_test_fs[top_k_features].copy()\n",
    "\n",
    "print(\"\\nMI sonrası şekiller:\")\n",
    "print(\"X_train_mi:\", X_train_mi.shape)\n",
    "print(\"X_val_mi:  \", X_val_mi.shape)\n",
    "print(\"X_test_mi: \", X_test_mi.shape)\n",
    "\n",
    "# 5) (Opsiyonel) MI skorlarını DataFrame olarak kaydet\n",
    "\n",
    "mi_df = mi_series.reset_index()\n",
    "mi_df.columns = [\"feature\", \"mi_score\"]\n",
    "mi_df.to_csv(\"../data/processed/feature_importance_mutual_info.csv\", index=False)\n",
    "\n",
    "X_train = X_train_mi\n",
    "y_train = y_train_fs\n",
    "\n",
    "X_val   = X_val_mi\n",
    "y_val   = y_val_fs\n",
    "\n",
    "X_test  = X_test_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72435c4e-278a-401d-87be-e20a0134e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ X_train_selected, y_train_final, X_val_encoded, y_val_final, X_test_encoded kaydedildi.\n",
      "✓ final_feature_list.json kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Klasör var mı kontrol et, yoksa oluştur\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# 1) Feature matrislerini kaydet\n",
    "\n",
    "# Modeling notebook'da beklenen isimlere göre kaydediyoruz\n",
    "# old ->>> X_train_mi.to_csv(\"../data/processed/X_train_smote.csv\", index=False)\n",
    "X_train_mi.to_csv(\"../data/processed/X_train_selected.csv\", index=False)\n",
    "\n",
    "X_val_mi.to_csv(\"../data/processed/X_val_encoded.csv\", index=False)\n",
    "X_test_mi.to_csv(\"../data/processed/X_test_encoded.csv\", index=False)\n",
    "\n",
    "# 2) Hedef (label) vektörlerini kaydet\n",
    "pd.DataFrame({\"Loan_Status\": y_train_final}).to_csv(\n",
    "    # old ->>>\"../data/processed/y_train_smote.csv\", index=False\n",
    "    \"../data/processed/y_train_final.csv\", index=False\n",
    ")\n",
    "pd.DataFrame({\"Loan_Status\": y_val_final}).to_csv(\n",
    "    \"../data/processed/y_val_final.csv\", index=False\n",
    ")\n",
    "\n",
    "print(\"✓ X_train_selected, y_train_final, X_val_encoded, y_val_final, X_test_encoded kaydedildi.\")\n",
    "\n",
    "# 3) Seçilmiş feature listesini ayrıca json olarak kaydet\n",
    "final_feature_list = list(X_train_mi.columns)\n",
    "\n",
    "with open(\"../data/processed/final_feature_list.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_feature_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✓ final_feature_list.json kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f35b727-cc25-4872-a4f9-96c8d2d002bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE öncesi sınıf dağılımı (Train): {1: 337, 0: 154}\n",
      "SMOTE sonrası sınıf dağılımı (Train): {1: 337, 0: 337}\n",
      "\n",
      "✓ Dosyalar başarıyla kaydedildi:\n",
      "  - Normal Train: X_train_selected.csv & y_train_final.csv\n",
      "  - SMOTE Train:  X_train_smote.csv & y_train_smote.csv\n",
      "  - Validation:   X_val_encoded.csv & y_val_final.csv\n",
      "  - Test:         X_test_encoded.csv\n",
      "✓ final_feature_list.json kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Klasör var mı kontrol et, yoksa oluştur\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# A) SMOTE Uygulama (Sadece Train Setine!)\n",
    "print(f\"SMOTE öncesi sınıf dağılımı (Train): {y_train_fs.value_counts().to_dict()}\")\n",
    "\n",
    "# SMOTE nesnesi\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# X_train_mi (Feature Selection yapılmış hali) üzerinde SMOTE uygula\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_mi, y_train_fs)\n",
    "\n",
    "# SMOTE çıktısı numpy array olabilir, DataFrame'e geri çevirelim (Feature isimlerini koruyarak)\n",
    "X_train_smote = pd.DataFrame(X_train_smote, columns=X_train_mi.columns)\n",
    "y_train_smote = pd.Series(y_train_smote, name=\"Loan_Status\")\n",
    "\n",
    "print(f\"SMOTE sonrası sınıf dağılımı (Train): {y_train_smote.value_counts().to_dict()}\")\n",
    "\n",
    "# B) Dosyaları Kaydetme\n",
    "\n",
    "# 1. Normal (Dengesiz - Orijinal) Eğitim Seti\n",
    "X_train_mi.to_csv(\"../data/processed/X_train_selected.csv\", index=False)\n",
    "y_train_fs.to_frame(\"Loan_Status\").to_csv(\"../data/processed/y_train_final.csv\", index=False)\n",
    "\n",
    "# 2. SMOTE Uygulanmış (Dengeli) Eğitim Seti\n",
    "X_train_smote.to_csv(\"../data/processed/X_train_smote.csv\", index=False)\n",
    "y_train_smote.to_frame(\"Loan_Status\").to_csv(\"../data/processed/y_train_smote.csv\", index=False)\n",
    "\n",
    "# 3. Validation ve Test Setleri (Asla SMOTE uygulanmaz!)\n",
    "X_val_mi.to_csv(\"../data/processed/X_val_encoded.csv\", index=False)\n",
    "y_val_fs.to_frame(\"Loan_Status\").to_csv(\"../data/processed/y_val_final.csv\", index=False)\n",
    "\n",
    "X_test_mi.to_csv(\"../data/processed/X_test_encoded.csv\", index=False)\n",
    "# Test setinin label'ı (y_test) yarışma formatında olduğu için genelde yoktur veya ayrı tutulur.\n",
    "# Eğer elinde y_test varsa onu da kaydedebilirsin.\n",
    "\n",
    "print(\"\\n✓ Dosyalar başarıyla kaydedildi:\")\n",
    "print(\"  - Normal Train: X_train_selected.csv & y_train_final.csv\")\n",
    "print(\"  - SMOTE Train:  X_train_smote.csv & y_train_smote.csv\")\n",
    "print(\"  - Validation:   X_val_encoded.csv & y_val_final.csv\")\n",
    "print(\"  - Test:         X_test_encoded.csv\")\n",
    "\n",
    "# C) Metadata Kaydı\n",
    "final_feature_list = list(X_train_mi.columns)\n",
    "\n",
    "with open(\"../data/processed/final_feature_list.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_feature_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✓ final_feature_list.json kaydedildi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
